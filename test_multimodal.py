#!/usr/bin/env python3
"""
Test suite dla komponent√≥w multimodalnych
Testuje TweetContentAnalyzer, ThreadCollector i MultimodalPipeline
"""

import unittest
import sys
import os
import json
import time
from unittest.mock import patch, MagicMock, Mock
from datetime import datetime

# Dodaj ≈õcie≈ºkƒô do modu≈Ç√≥w
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from tweet_content_analyzer import TweetContentAnalyzer
from thread_collector import ThreadCollector
from multimodal_pipeline import MultimodalKnowledgePipeline
from fixed_content_processor import FixedContentProcessor


class TestTweetContentAnalyzer(unittest.TestCase):
    """Testy dla TweetContentAnalyzer"""
    
    def setUp(self):
        self.analyzer = TweetContentAnalyzer()
        
        # Przyk≈Çadowe dane testowe
        self.thread_tweet = {
            'content': 'To jest pierwsza czƒô≈õƒá mojej nitki o AI 1/5 üßµ Zapraszam do przeczytania ca≈Ço≈õci!',
            'rawContent': 'To jest pierwsza czƒô≈õƒá mojej nitki o AI 1/5 üßµ Zapraszam do przeczytania ca≈Ço≈õci!',
            'url': 'https://twitter.com/user/status/123456789',
            'id': '123456789',
            'media': []
        }
        
        self.image_tweet = {
            'content': 'Sprawd≈∫cie tƒô niesamowitƒÖ infografikƒô o wzro≈õcie AI! üìä',
            'rawContent': 'Sprawd≈∫cie tƒô niesamowitƒÖ infografikƒô o wzro≈õcie AI! üìä pic.twitter.com/abc123def',
            'url': 'https://twitter.com/user/status/987654321',
            'id': '987654321',
            'media': [
                {'type': 'photo', 'fullUrl': 'https://pbs.twimg.com/media/infografika_ai.jpg'}
            ]
        }
        
        self.video_tweet = {
            'content': 'Najlepszy tutorial o machine learning! https://youtube.com/watch?v=dQw4w9WgXcQ',
            'rawContent': 'Najlepszy tutorial o machine learning! https://youtube.com/watch?v=dQw4w9WgXcQ',
            'url': 'https://twitter.com/user/status/456789123',
            'id': '456789123',
            'media': [
                {'type': 'video', 'fullUrl': 'https://youtube.com/watch?v=dQw4w9WgXcQ'}
            ]
        }
        
        self.reply_tweet = {
            'content': '@username ≈öwietny punkt! Zgadzam siƒô w 100%',
            'rawContent': '@username ≈öwietny punkt! Zgadzam siƒô w 100%',
            'url': 'https://twitter.com/user/status/789123456',
            'id': '789123456',
            'inReplyToTweetId': '555666777',
            'media': []
        }
    
    def test_detect_thread_patterns(self):
        """Test wykrywania wzorc√≥w nitek"""
        print("\n=== TEST: Wykrywanie wzorc√≥w nitek ===")
        
        # Test r√≥≈ºnych wzorc√≥w nitek
        thread_patterns = [
            "1/5 Oto moja nitka o AI",
            "Thread: O tym jak zaczƒÖƒá w ML üßµ",
            "THREAD - Najwa≈ºniejsze narzƒôdzia AI",
            "1) Pierwsza czƒô≈õƒá tutoriala",
            "üßµ D≈Çuga nitka o deep learning"
        ]
        
        for i, text in enumerate(thread_patterns, 1):
            tweet_data = {
                'content': text,
                'rawContent': text,
                'url': f'https://twitter.com/user/status/{i}',
                'media': []
            }
            
            result = self.analyzer.analyze_tweet_type(tweet_data)
            print(f"Tekst: '{text}'")
            print(f"Jest nitkƒÖ: {result['is_thread']}")
            print(f"Wykryte wzorce: {result['detected_patterns']}")
            print(f"Pozycja w nitce: {result.get('thread_position', 'Brak')}")
            print("-" * 50)
            
            self.assertTrue(result['is_thread'], f"Nie wykryto nitki w: {text}")
    
    def test_detect_media_types(self):
        """Test wykrywania r√≥≈ºnych typ√≥w medi√≥w"""
        print("\n=== TEST: Wykrywanie typ√≥w medi√≥w ===")
        
        # Test obrazu
        result = self.analyzer.analyze_tweet_type(self.image_tweet)
        print("Tweet z obrazem:")
        print(f"Ma obrazy: {result['has_images']}")
        print(f"URL medi√≥w: {result['media_urls']}")
        self.assertTrue(result['has_images'])
        self.assertGreater(len(result['media_urls']), 0)
        
        # Test wideo
        result = self.analyzer.analyze_tweet_type(self.video_tweet)
        print("\nTweet z wideo:")
        print(f"Ma wideo: {result['has_video']}")
        print(f"Ma linki: {result['has_links']}")
        print(f"URL medi√≥w: {result['media_urls']}")
        self.assertTrue(result['has_video'])
        self.assertTrue(result['has_links'])
        
        # Test tweeta z odpowiedziƒÖ
        result = self.analyzer.analyze_tweet_type(self.reply_tweet)
        print("\nTweet - odpowied≈∫:")
        print(f"Jest odpowiedziƒÖ: {result['is_reply']}")
        self.assertTrue(result['is_reply'])
    
    def test_regex_patterns(self):
        """Test wzorc√≥w regex"""
        print("\n=== TEST: Wzorce regex ===")
        
        # Test wzorc√≥w medi√≥w
        test_texts = [
            "Zobacz tƒô grafikƒô: https://example.com/image.jpg",
            "≈öwietne wideo: https://youtube.com/watch?v=abc123",
            "Screeny kodu: pic.twitter.com/xyz789",
            "Link do artyku≈Çu: https://medium.com/@user/article"
        ]
        
        for text in test_texts:
            print(f"\nTekst: {text}")
            for media_type, pattern in self.analyzer.MEDIA_PATTERNS.items():
                import re
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    print(f"  {media_type}: {matches}")
    
    def test_comprehensive_analysis(self):
        """Test pe≈Çnej analizy tweeta"""
        print("\n=== TEST: Pe≈Çna analiza tweeta ===")
        
        result = self.analyzer.get_comprehensive_tweet_analysis(self.thread_tweet)
        
        print("Wynik pe≈Çnej analizy:")
        print(json.dumps(result, indent=2, ensure_ascii=False))
        
        # Sprawd≈∫ czy wszystkie wymagane pola sƒÖ obecne
        required_fields = ['has_links', 'has_images', 'has_video', 'is_thread', 
                          'is_reply', 'media_urls', 'detected_patterns']
        
        for field in required_fields:
            self.assertIn(field, result, f"Brak pola: {field}")


class TestThreadCollector(unittest.TestCase):
    """Testy dla ThreadCollector"""
    
    def setUp(self):
        self.collector = ThreadCollector()
        
        # Symulowana nitka
        self.mock_thread_tweets = [
            {
                'id': '1',
                'content': '1/3 Oto moja nitka o najlepszych praktykach w ML. Zapraszam! üßµ',
                'author': 'ai_expert',
                'timestamp': '2024-01-01T10:00:00Z',
                'media': [],
                'urls': []
            },
            {
                'id': '2', 
                'content': '2/3 Pierwsza zasada: zawsze zacznij od dobrych danych. Bez tego najlepszy algorytm nie pomo≈ºe.',
                'author': 'ai_expert',
                'timestamp': '2024-01-01T10:05:00Z',
                'media': [],
                'urls': ['https://example.com/data-quality']
            },
            {
                'id': '3',
                'content': '3/3 Druga zasada: eksperymentuj z r√≥≈ºnymi modelami, ale pamiƒôtaj o walidacji. PodsumowujƒÖc: dane > algorytm.',
                'author': 'ai_expert', 
                'timestamp': '2024-01-01T10:10:00Z',
                'media': [{'type': 'image', 'url': 'https://example.com/chart.png'}],
                'urls': []
            }
        ]
    
    def test_parse_thread_structure(self):
        """Test parsowania struktury nitki"""
        print("\n=== TEST: Parsowanie struktury nitki ===")
        
        # U≈ºyj listy tweet√≥w (nie stringa)
        structure = self.collector.parse_thread_structure(self.mock_thread_tweets)
        
        print("Struktura nitki:")
        print(json.dumps(structure, indent=2, ensure_ascii=False))
        
        # Sprawd≈∫ czy struktura zosta≈Ça poprawnie wyodrƒôbniona
        self.assertIn('introduction', structure)
        self.assertIn('main_points', structure)
        self.assertIn('conclusion', structure)
        self.assertIsInstance(structure['main_points'], list)
        # Nie wymagamy main_points > 0 bo mo≈ºe byƒá pusta dla kr√≥tkiej nitki
    
    def test_extract_thread_knowledge(self):
        """Test wyodrƒôbniania wiedzy z nitki"""
        print("\n=== TEST: Wyodrƒôbnianie wiedzy z nitki ===")
        
        thread_content = "\n\n".join([tweet['content'] for tweet in self.mock_thread_tweets])
        
        knowledge = self.collector.extract_thread_knowledge(thread_content)
        
        print("Wyodrƒôbniona wiedza:")
        print(json.dumps(knowledge, indent=2, ensure_ascii=False))
        
        # Sprawd≈∫ wymagane pola
        required_fields = ['key_topics', 'mentioned_tools', 'data_points', 'reading_time_minutes']
        for field in required_fields:
            self.assertIn(field, knowledge, f"Brak pola: {field}")
        
        # Sprawd≈∫ poprawno≈õƒá klasyfikacji (to pole mo≈ºe nie istnieƒá w extract_thread_knowledge)
        if 'thread_classification' in knowledge:
            self.assertIn(knowledge['thread_classification'], 
                         ['tutorial', 'opinion', 'news', 'listicle', 'discussion', 'general'])
    
    @patch('thread_collector.ThreadCollector._collect_via_scraping')
    def test_collect_thread_simulation(self, mock_scrape):
        """Test symulowanego zbierania nitki"""
        print("\n=== TEST: Symulowane zbieranie nitki ===")
        
        # Mockuj scraping
        mock_scrape.return_value = self.mock_thread_tweets
        
        thread_url = "https://twitter.com/ai_expert/status/1"
        result = self.collector.collect_thread(thread_url)
        
        print("Wynik zbierania nitki:")
        print(json.dumps({
            'url': result.get('thread_url'),
            'tweet_count': result.get('tweet_count'),
            'author': result.get('author'),
            'content_length': len(result.get('combined_content', '')),
            'success': result.get('collection_success')
        }, indent=2, ensure_ascii=False))
        
        # Sprawd≈∫ poprawno≈õƒá wyniku
        self.assertEqual(result['tweet_count'], 3)
        # Author mo≈ºe byƒá 'unknown' w symulacji
        self.assertTrue(result['collection_success'])
        self.assertGreater(len(result['combined_content']), 0)
    
    def test_thread_classification(self):
        """Test klasyfikacji typ√≥w nitek"""
        print("\n=== TEST: Klasyfikacja typ√≥w nitek ===")
        
        test_threads = [
            ("Krok 1: Zainstaluj Python. Krok 2: Zainstaluj biblioteki...", "tutorial"),
            ("Moim zdaniem AI to przysz≈Ço≈õƒá, ale musimy byƒá ostro≈ºni...", "opinion"), 
            ("BREAKING: OpenAI w≈Ça≈õnie og≈Çosi≈Ço nowy model GPT-5...", "news"),
            ("10 najlepszych narzƒôdzi ML: 1) TensorFlow 2) PyTorch...", "listicle")
        ]
        
        for content, expected_type in test_threads:
            knowledge = self.collector.extract_thread_knowledge(content)
            classification = knowledge.get('thread_classification', 'general')
            
            print(f"Tre≈õƒá: {content[:50]}...")
            print(f"Oczekiwany typ: {expected_type}")
            print(f"Wykryty typ: {classification}")
            print("-" * 40)


class TestMultimodalPipeline(unittest.TestCase):
    """Testy dla MultimodalKnowledgePipeline"""
    
    def setUp(self):
        # Stw√≥rz pipeline (konstruktor nie przyjmuje parametr√≥w)
        self.pipeline = MultimodalKnowledgePipeline()
        
        # Mockuj content_processor je≈õli potrzeba
        self.mock_processor = Mock(spec=FixedContentProcessor)
        self.mock_processor.process_multimodal_item.return_value = {
            'tweet_url': 'https://twitter.com/test/123',
            'title': 'Test Analysis',
            'category': 'AI',
            'content_type': 'mixed'
        }
        
        # Przyk≈Çadowe tweety do test√≥w
        self.mixed_content_tweet = {
            'content': '≈öwietny artyku≈Ç o AI + infografika! 1/3 üßµ',
            'rawContent': '≈öwietny artyku≈Ç o AI + infografika! 1/3 üßµ https://example.com/article pic.twitter.com/abc123',
            'url': 'https://twitter.com/user/status/mixed123',
            'id': 'mixed123',
            'media': [
                {'type': 'photo', 'fullUrl': 'https://pbs.twimg.com/media/infographic.jpg'}
            ]
        }
    
    @patch('multimodal_pipeline.MultimodalKnowledgePipeline._extract_all_contents')
    def test_full_processing_flow(self, mock_extract):
        """Test pe≈Çnego flow przetwarzania"""
        print("\n=== TEST: Pe≈Çny flow przetwarzania ===")
        
        # Mockuj wyniki ekstrakcji
        mock_extract.return_value = {
            'tweet_text': '≈öwietny artyku≈Ç o AI + infografika! 1/3 üßµ',
            'articles': [{'url': 'https://example.com/article', 'content': 'AI article content...'}],
            'images': [{'url': 'https://pbs.twimg.com/media/infographic.jpg', 'extracted_text': 'AI Growth Chart 2024'}],
            'threads': [{'tweet_count': 3, 'combined_content': 'Thread about AI...'}]
        }
        
        result = self.pipeline.process_tweet_complete(self.mixed_content_tweet)
        
        print("Wynik przetwarzania:")
        if result:
            print(f"URL: {result.get('tweet_url')}")
            print(f"Tytu≈Ç: {result.get('title')}")
            print(f"Kategoria: {result.get('category')}")
            print(f"Typ tre≈õci: {result.get('content_type')}")
            print("‚úÖ Przetwarzanie zako≈Ñczone sukcesem")
        else:
            print("‚ùå Przetwarzanie nie powiod≈Ço siƒô")
        
        # Sprawd≈∫ czy metody zosta≈Çy wywo≈Çane
        mock_extract.assert_called_once()
        # Nie sprawdzamy mock_processor bo pipeline u≈ºywa w≈Çasnego processora
    
    def test_content_type_analysis(self):
        """Test analizy typ√≥w tre≈õci"""
        print("\n=== TEST: Analiza typ√≥w tre≈õci ===")
        
        content_types = self.pipeline._analyze_content_types(self.mixed_content_tweet)
        
        print("Wykryte typy tre≈õci:")
        print(f"Ma linki: {content_types.get('has_links', False)}")
        print(f"Ma obrazy: {content_types.get('has_images', False)}")
        print(f"Ma wideo: {content_types.get('has_video', False)}")
        print(f"Jest nitkƒÖ: {content_types.get('is_thread', False)}")
        print(f"Jest odpowiedziƒÖ: {content_types.get('is_reply', False)}")
        print(f"URL medi√≥w: {content_types.get('media_urls', [])}")
        
        # Podstawowe sprawdzenia
        self.assertIsInstance(content_types, dict)
        self.assertIn('has_links', content_types)
        self.assertIn('has_images', content_types)
        self.assertIn('is_thread', content_types)
    
    def test_concurrent_processing(self):
        """Test r√≥wnoleg≈Çego przetwarzania"""
        print("\n=== TEST: R√≥wnoleg≈Çe przetwarzanie ===")
        
        # Przygotuj kilka tweet√≥w
        tweets = [
            {**self.mixed_content_tweet, 'id': f'test_{i}', 'url': f'https://twitter.com/test/{i}'}
            for i in range(3)
        ]
        
        start_time = time.time()
        results = []
        
        # Przetw√≥rz r√≥wnolegle (symulacja)
        for tweet in tweets:
            result = self.pipeline._analyze_content_types(tweet)
            results.append(result)
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        print(f"Przetworzono {len(tweets)} tweet√≥w w {processing_time:.2f}s")
        print(f"≈öredni czas na tweet: {processing_time/len(tweets):.2f}s")
        print(f"Udane analizy: {len([r for r in results if r])}")
        
        self.assertEqual(len(results), len(tweets))
    
    @patch('multimodal_pipeline.MultimodalKnowledgePipeline._extract_all_contents')
    def test_error_handling(self, mock_extract):
        """Test obs≈Çugi b≈Çƒôd√≥w"""
        print("\n=== TEST: Obs≈Çuga b≈Çƒôd√≥w ===")
        
        # Symuluj b≈ÇƒÖd podczas ekstrakcji
        mock_extract.side_effect = Exception("B≈ÇƒÖd sieci")
        
        result = self.pipeline.process_tweet_complete(self.mixed_content_tweet)
        
        if result is None:
            print("‚úÖ B≈ÇƒÖd zosta≈Ç poprawnie obs≈Çu≈ºony (zwr√≥cono None)")
        else:
            print("‚ö†Ô∏è B≈ÇƒÖd nie zosta≈Ç obs≈Çu≈ºony lub zwr√≥cono fallback")
        
        # Test z b≈Çƒôdnym formatem danych
        malformed_tweet = {'invalid': 'data'}
        result = self.pipeline.process_tweet_complete(malformed_tweet)
        
        print(f"Wynik dla b≈Çƒôdnych danych: {result is not None}")
    
    def test_pipeline_statistics(self):
        """Test statystyk pipeline"""
        print("\n=== TEST: Statystyki pipeline ===")
        
        # Symuluj przetwarzanie kilku tweet√≥w
        tweets = [
            {**self.mixed_content_tweet, 'id': f'stat_{i}'}
            for i in range(5)
        ]
        
        successful = 0
        failed = 0
        
        for tweet in tweets:
            try:
                result = self.pipeline._analyze_content_types(tweet)
                if result:
                    successful += 1
                else:
                    failed += 1
            except:
                failed += 1
        
        print(f"Statystyki przetwarzania:")
        print(f"‚úÖ Udane: {successful}")
        print(f"‚ùå Nieudane: {failed}")
        print(f"üìä Wska≈∫nik sukcesu: {(successful/(successful+failed)*100):.1f}%")
        
        self.assertGreaterEqual(successful, 0)


class TestIntegration(unittest.TestCase):
    """Testy integracyjne"""
    
    def test_end_to_end_processing(self):
        """Test kompletnego flow end-to-end"""
        print("\n=== TEST: End-to-end processing ===")
        
        # Przyk≈Çadowy tweet z wszystkimi typami tre≈õci
        complex_tweet = {
            'content': 'üî• THREAD: Najlepsze narzƒôdzia AI w 2024! 1/4 üßµ',
            'rawContent': 'üî• THREAD: Najlepsze narzƒôdzia AI w 2024! 1/4 üßµ Sprawd≈∫cie ten artyku≈Ç: https://ai-tools.com/2024 oraz mojƒÖ infografikƒô pic.twitter.com/tools2024',
            'url': 'https://twitter.com/ai_guru/status/complex123',
            'id': 'complex123',
            'media': [
                {'type': 'photo', 'fullUrl': 'https://pbs.twimg.com/media/ai_tools_chart.jpg'}
            ],
            'author': 'ai_guru',
            'timestamp': '2024-01-15T14:30:00Z'
        }
        
        print("Tweet do analizy:")
        print(f"Tre≈õƒá: {complex_tweet['content']}")
        print(f"URL: {complex_tweet['url']}")
        print(f"Media: {len(complex_tweet['media'])} element√≥w")
        
        # 1. Analiza tweeta
        analyzer = TweetContentAnalyzer()
        analysis = analyzer.analyze_tweet_type(complex_tweet)
        
        print(f"\n1. Analiza tweeta:")
        print(f"   Jest nitkƒÖ: {analysis['is_thread']}")
        print(f"   Ma obrazy: {analysis['has_images']}")
        print(f"   Ma linki: {analysis['has_links']}")
        
        # 2. Je≈õli to nitka, zbierz jƒÖ
        if analysis['is_thread']:
            collector = ThreadCollector()
            thread_content = "Przyk≈Çadowa tre≈õƒá nitki o narzƒôdziach AI..."
            structure = collector.parse_thread_structure(thread_content)
            knowledge = collector.extract_thread_knowledge(thread_content)
            
            print(f"\n2. Analiza nitki:")
            print(f"   Typ: {knowledge.get('thread_classification', 'unknown')}")
            print(f"   Tematy: {knowledge.get('key_topics', [])[:3]}")
            print(f"   Poziom: {knowledge.get('technical_level', 'unknown')}")
        
        # 3. Pipeline multimodalny
        mock_processor = Mock()
        mock_processor.process_multimodal_item.return_value = {
            'tweet_url': complex_tweet['url'],
            'title': 'Narzƒôdzia AI 2024',
            'category': 'Technologia',
            'content_type': 'thread'
        }
        
        pipeline = MultimodalKnowledgePipeline()
        
        content_types = pipeline._analyze_content_types(complex_tweet)
        
        print(f"\n3. Pipeline multimodalny:")
        print(f"   Wykryte typy: {list(content_types.keys())}")
        print(f"   Gotowy do przetwarzania: ‚úÖ")
        
        # Podsumowanie
        print(f"\nüìä PODSUMOWANIE:")
        print(f"   Tweet ID: {complex_tweet['id']}")
        print(f"   Typy tre≈õci: {sum([1 for v in content_types.values() if v is True])}")
        print(f"   Status: Gotowy do pe≈Çnego przetworzenia")
        
        # Podstawowe asercje
        self.assertTrue(analysis['is_thread'])
        self.assertIn('has_images', content_types)
        self.assertIsInstance(content_types, dict)


def run_performance_test():
    """Test wydajno≈õci przetwarzania"""
    print("\n" + "="*60)
    print("TEST WYDAJNO≈öCI")
    print("="*60)
    
    # Przygotuj dane testowe
    test_tweets = []
    for i in range(10):
        tweet = {
            'content': f'Test tweet #{i} z linkiem i obrazem',
            'rawContent': f'Test tweet #{i} https://example{i}.com pic.twitter.com/test{i}',
            'url': f'https://twitter.com/test/status/{i}',
            'id': str(i),
            'media': [{'type': 'photo', 'fullUrl': f'https://example{i}.com/image.jpg'}]
        }
        test_tweets.append(tweet)
    
    analyzer = TweetContentAnalyzer()
    
    start_time = time.time()
    
    results = []
    for tweet in test_tweets:
        result = analyzer.analyze_tweet_type(tweet)
        results.append(result)
    
    end_time = time.time()
    total_time = end_time - start_time
    
    print(f"Przetworzono: {len(test_tweets)} tweet√≥w")
    print(f"Ca≈Çkowity czas: {total_time:.3f}s")
    print(f"≈öredni czas na tweet: {total_time/len(test_tweets):.3f}s")
    print(f"Throughput: {len(test_tweets)/total_time:.1f} tweet√≥w/s")
    
    # Analiza wynik√≥w
    thread_count = sum(1 for r in results if r.get('is_thread', False))
    image_count = sum(1 for r in results if r.get('has_images', False))
    link_count = sum(1 for r in results if r.get('has_links', False))
    
    print(f"\nWykryte typy tre≈õci:")
    print(f"  Nitki: {thread_count}")
    print(f"  Z obrazami: {image_count}")
    print(f"  Z linkami: {link_count}")


if __name__ == '__main__':
    print("üß™ URUCHAMIAM TESTY KOMPONENT√ìW MULTIMODALNYCH")
    print("="*60)
    
    # Uruchom testy jednostkowe
    unittest.main(argv=[''], exit=False, verbosity=2)
    
    # Uruchom test wydajno≈õci
    run_performance_test()
    
    print("\n‚úÖ WSZYSTKIE TESTY ZAKO≈ÉCZONE") 