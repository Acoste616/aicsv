#!/usr/bin/env python3
"""
Skrypt diagnostyczny do testowania jakoÅ›ci analiz LLM
Pomaga zidentyfikowaÄ‡ problemy z generowaniem JSON
"""

import requests
import json
import time
from content_extractor import ContentExtractor

def test_single_tweet_analysis():
    """Testuje analizÄ™ pojedynczego tweeta z peÅ‚nym debugowaniem."""
    
    # PrzykÅ‚adowy tweet do testowania
    test_tweet = {
        'id': 'test_123',
        'full_text': 'Just discovered this amazing guide on building RAG systems with @LangChain! '
                     'The step-by-step approach to chunking strategies is gold ğŸ”¥ '
                     'https://t.co/example123 #AI #RAG #LangChain',
        'created_at': '2024-11-15 10:00:00'
    }
    
    print("TEST ANALIZY POJEDYNCZEGO TWEETA")
    print("=" * 50)
    print(f"Tweet: {test_tweet['full_text'][:100]}...")
    
    # Test 1: Ekstrakcja treÅ›ci
    print("\nğŸ“„ TEST 1: Ekstrakcja treÅ›ci ze strony...")
    extractor = ContentExtractor()
    
    # Lista URL do testowania - prawdziwe linki z tweetÃ³w (rÃ³Å¼ne typy treÅ›ci)
    test_urls = [
        "https://t.co/0lLjxGSCue",  # Nowy link testowy 1
        "https://t.co/d0wPyTGnDh",  # Nowy link testowy 2
        "https://t.co/FCUsmol5XR",  # Poprzedni dziaÅ‚ajÄ…cy
        "https://github.com/langchain-ai/langchain",  # GitHub - referencyjny
        "https://openai.com/blog/chatgpt",  # OpenAI - trudny przypadek
    ]
    
    content = ""
    success_count = 0
    total_chars = 0
    
    for i, test_url in enumerate(test_urls, 1):
        print(f"\nğŸ”— URL {i}/{len(test_urls)}: {test_url}")
        content = extractor.extract_with_retry(test_url, max_retries=2)
    
        
        if content and len(content) > 100:  # ObniÅ¼ony prÃ³g
            char_count = len(content)
            total_chars += char_count
            print(f"âœ… Pobrano {char_count} znakÃ³w")
            print(f"ğŸ“ Fragment: {content[:200]}...")
            
            # SprawdÅº jakoÅ›Ä‡ treÅ›ci
            if char_count < 200:
                print("âš ï¸  TreÅ›Ä‡ krÃ³tka - moÅ¼e byÄ‡ niepeÅ‚na")
            elif "javascript" in content.lower()[:200]:
                print("âš ï¸  MoÅ¼liwy komunikat o bÅ‚Ä™dzie JavaScript!")
            elif "treÅ›Ä‡ niedostÄ™pna" in content.lower():
                print("âš ï¸  TreÅ›Ä‡ niedostÄ™pna - strona blokuje boty")
            elif char_count > 500:
                print("âœ… TreÅ›Ä‡ wyglÄ…da bardzo dobrze!")
                success_count += 1
            else:
                print("âœ… TreÅ›Ä‡ wyglÄ…da dobrze!")
                success_count += 1
                
            # UÅ¼yj pierwszej dobrej treÅ›ci do dalszej analizy
            if char_count > 300:
                break
        else:
            print(f"âŒ NiewystarczajÄ…ca treÅ›Ä‡ ({len(content) if content else 0} znakÃ³w)")
    
    # JeÅ›li Å¼aden URL nie zadziaÅ‚aÅ‚, uÅ¼yj dummy content
    if not content or len(content) < 300:
        print("\nâš ï¸  UÅ¼ywam przykÅ‚adowej treÅ›ci do testÃ³w...")
        content = """
        LangChain is a framework for developing applications powered by language models. 
        It enables applications that are context-aware and can reason. The framework provides 
        modular components for working with LLMs, including prompt templates, chains, agents, 
        and memory systems. This guide covers RAG (Retrieval Augmented Generation) implementation 
        with best practices for chunking strategies, vector stores, and retrieval optimization.
        """
    
    # Test 2: Prompt Generation
    print("\nğŸ¯ TEST 2: Generowanie prompta...")
    prompt = create_test_prompt(test_tweet['full_text'], content)
    print(f"ğŸ“ DÅ‚ugoÅ›Ä‡ prompta: {len(prompt)} znakÃ³w")
    
    # Test 3: LLM Query
    print("\nğŸ¤– TEST 3: Zapytanie do LLM...")
    
    for temperature in [0.3, 0.5, 0.7]:
        print(f"\n--- Testowanie z temperature={temperature} ---")
        response = query_llm_test(prompt, temperature)
        
        if response:
            print(f"âœ… Otrzymano odpowiedÅº ({len(response)} znakÃ³w)")
            
            # PrÃ³ba parsowania JSON
            json_data = extract_json(response)
            if json_data:
                print("âœ… JSON parsed successfully!")
                print(json.dumps(json_data, indent=2, ensure_ascii=False)[:500])
                
                # Walidacja jakoÅ›ci
                quality_score = validate_quality(json_data)
                print(f"\nğŸ“Š Ocena jakoÅ›ci: {quality_score}/10")
                
                if quality_score < 7:
                    print("âš ï¸ Niska jakoÅ›Ä‡ - sprawdÅº:")
                    print("  - Czy treÅ›Ä‡ artykuÅ‚u jest poprawnie pobrana?")
                    print("  - Czy prompt zawiera doÅ›Ä‡ kontekstu?")
                    print("  - Czy model nie jest przeciÄ…Å¼ony?")
            else:
                print("âŒ Nie udaÅ‚o siÄ™ sparsowaÄ‡ JSON!")
                print(f"OdpowiedÅº: {response[:300]}...")
        else:
            print("âŒ Brak odpowiedzi od LLM")
        
        time.sleep(2)
    
    # Podsumowanie testÃ³w ekstrakcji treÅ›ci
    print(f"\n{'='*60}")
    print("ğŸ“Š PODSUMOWANIE EKSTRAKCJI TREÅšCI")
    print(f"{'='*60}")
    print(f"âœ… Sukces: {success_count}/{len(test_urls)} ({(success_count/len(test_urls))*100:.0f}%)")
    print(f"ğŸ“ Åšrednia dÅ‚ugoÅ›Ä‡: {total_chars//len(test_urls) if total_chars > 0 else 0} znakÃ³w")
    print(f"ğŸ“ˆ ÅÄ…czna treÅ›Ä‡: {total_chars} znakÃ³w")
    
    if success_count >= 4:
        print("ğŸ‰ DOSKONAÅY WYNIK! Ekstrakcja treÅ›ci dziaÅ‚a Å›wietnie!")
    elif success_count >= 3:
        print("âœ… DOBRY WYNIK! WiÄ™kszoÅ›Ä‡ stron dziaÅ‚a poprawnie")
    elif success_count >= 2:
        print("âš ï¸  ÅšREDNI WYNIK - wymaga dalszych optymalizacji")
    else:
        print("âŒ SÅABY WYNIK - potrzebne powaÅ¼ne poprawki ekstraktora")
    
    extractor.close()

def create_test_prompt(tweet_text, article_content):
    """Tworzy prompt testowy."""
    return f"""JesteÅ› ekspertem w analizie treÅ›ci. Przeanalizuj tweet i artykuÅ‚.

Tweet: {tweet_text}

ArtykuÅ‚: {article_content[:1500] if article_content else "Brak treÅ›ci"}

StwÃ³rz analizÄ™ w formacie JSON z polami:
- title: konkretny tytuÅ‚ (max 10 sÅ‚Ã³w)
- summary: opis 2-3 zdania
- keywords: lista 5-7 sÅ‚Ã³w kluczowych
- category: jedna z ["Technologia", "Nauka", "Biznes", "SpoÅ‚eczne", "Inne"]
- sentiment: ["Pozytywny", "Neutralny", "Negatywny"]
- estimated_reading_time_minutes: liczba
- difficulty: ["Åatwy", "Åšredni", "Trudny"]
- key_takeaways: lista 3-5 wnioskÃ³w

Odpowiedz TYLKO poprawnym JSON, bez dodatkowego tekstu."""

def query_llm_test(prompt, temperature):
    """Testowe zapytanie do LLM."""
    try:
        response = requests.post(
            "http://localhost:1234/v1/chat/completions",
            json={
                "model": "mistralai/mistral-7b-instruct-v0.3",
                "messages": [{"role": "user", "content": prompt}],
                "temperature": temperature,
                "max_tokens": 800,
                "stream": False
            },
            timeout=30
        )
        
        if response.status_code == 200:
            return response.json()['choices'][0]['message']['content']
    except Exception as e:
        print(f"BÅ‚Ä…d: {e}")
    
    return None

def extract_json(text):
    """WyciÄ…ga JSON z tekstu."""
    import re
    
    if not text:
        return None

    # Metoda 1: markdown block
    match = re.search(r'```(?:json)?\s*(\\{.*?\\})\s*```', text, re.DOTALL)
    if match:
        try:
            return json.loads(match.group(1))
        except:
            pass
    
    # Metoda 2: znajdÅº JSON
    start = text.find('{')
    end = text.rfind('}')
    
    if start != -1 and end != -1:
        try:
            return json.loads(text[start:end+1])
        except:
            pass
    
    return None

def validate_quality(data):
    """Ocenia jakoÅ›Ä‡ analizy (0-10)."""
    score = 0
    
    if not data:
        return 0

    # SprawdÅº obecnoÅ›Ä‡ pÃ³l
    required_fields = ['title', 'summary', 'keywords', 'category', 'key_takeaways']
    for field in required_fields:
        if field in data and data[field]:
            score += 1
    
    # SprawdÅº jakoÅ›Ä‡
    if len(data.get('title', '')) > 10:
        score += 1
    if len(data.get('summary', '')) > 50:
        score += 1
    if len(data.get('keywords', [])) >= 5:
        score += 1
    if len(data.get('key_takeaways', [])) >= 3:
        score += 1
    
    # SprawdÅº czy nie jest generyczne
    generic_terms = ['javascript', 'bÅ‚Ä…d', 'nie dostÄ™pny', 'brak treÅ›ci']
    summary_lower = str(data.get('summary', '')).lower()
    title_lower = str(data.get('title', '')).lower()

    if not any(term in title_lower for term in generic_terms) and \
       not any(term in summary_lower for term in generic_terms):
        score += 1
    
    return score

def test_llm_variations():
    """Testuje rÃ³Å¼ne warianty promptÃ³w."""
    print("\nğŸ”¬ TEST RÃ“Å»NYCH PROMPTÃ“W")
    print("=" * 50)
    
    test_content = """
    OpenAI announced Canvas, a new interface for working with ChatGPT that enables 
    real-time collaboration on coding projects. Users can now edit code directly 
    within the interface, receive inline suggestions, and iterate on projects 
    without constantly copying and pasting. The feature supports multiple 
    programming languages and includes automatic formatting.
    """
    
    prompts = [
        # Prosty prompt
        "Analyze this: " + test_content + "\nReturn JSON with title, summary, keywords.",
        
        # SzczegÃ³Å‚owy prompt
        f"""You are analyzing tech content. Create a JSON analysis:
{test_content}

Required JSON structure:
{{"title": "...", "summary": "...", "keywords": [...], "category": "..."}}""",
        
        # Z przykÅ‚adem
        f"""Example output: {{"title": "AI Breakthrough", "summary": "New model", "keywords": ["AI"]}}

Now analyze: {test_content}

Output JSON:"""
    ]
    
    for i, prompt in enumerate(prompts, 1):
        print(f"\n--- Prompt {i} ---")
        response = query_llm_test(prompt, 0.5)
        if response:
            print(f"Response: {response[:200]}...")
            if extract_json(response):
                print("âœ… Valid JSON generated")
            else:
                print("âŒ Invalid JSON")
        time.sleep(2)

def diagnose_content_extraction():
    """Diagnozuje problemy z ekstrakcjÄ… treÅ›ci."""
    print("\nğŸ” DIAGNOZA EKSTRAKCJI TREÅšCI")
    print("=" * 50)
    
    test_urls = [
        "https://t.co/0lLjxGSCue",  # Nowy link testowy 1
        "https://t.co/d0wPyTGnDh",  # Nowy link testowy 2
        "https://t.co/FCUsmol5XR",  # Poprzedni dziaÅ‚ajÄ…cy
        "https://github.com/langchain-ai/langchain",  # GitHub - referencyjny
        "https://openai.com/blog/chatgpt",  # OpenAI - trudny
    ]
    
    extractor = ContentExtractor()
    
    for url in test_urls:
        print(f"\nğŸ“ Testowanie: {url}")
        content = extractor.extract_with_retry(url)
        
        if content:
            print(f"âœ… Sukces: {len(content)} znakÃ³w")
            # SprawdÅº jakoÅ›Ä‡
            if "javascript" in content.lower() and len(content) < 200:
                print("âš ï¸ MoÅ¼liwy bÅ‚Ä…d JS - treÅ›Ä‡ zbyt krÃ³tka")
            if "<" in content and ">" in content:
                print("âš ï¸ MoÅ¼liwe tagi HTML w treÅ›ci")
        else:
            print("âŒ Brak treÅ›ci")
    
    extractor.close()

def compare_extraction_methods():
    """PorÃ³wnuje starÄ… i nowÄ… metodÄ™ ekstrakcji."""
    print("\nğŸ”¬ PORÃ“WNANIE METOD EKSTRAKCJI")
    print("=" * 50)
    
    test_urls = [
        ("Twitter Link 1", "https://t.co/0lLjxGSCue"),
        ("Twitter Link 2", "https://t.co/d0wPyTGnDh"), 
        ("Twitter Link 3", "https://t.co/FCUsmol5XR"),
        ("GitHub LangChain", "https://github.com/langchain-ai/langchain"),
        ("OpenAI ChatGPT", "https://openai.com/blog/chatgpt"),
    ]
    
    extractor = ContentExtractor()
    
    for name, url in test_urls:
        print(f"\nğŸ“ {name} ({url})")
        print("-" * 40)
        
        # Test 1: Podstawowa metoda (jeden raz)
        start_time = time.time()
        basic_content = extractor.get_webpage_content(url)
        basic_time = time.time() - start_time
        
        print(f"Podstawowa metoda (1 prÃ³ba):")
        print(f"  â±ï¸  Czas: {basic_time:.2f}s")
        print(f"  ğŸ“ DÅ‚ugoÅ›Ä‡: {len(basic_content)} znakÃ³w")
        
        if len(basic_content) < 300:
            print(f"  âš ï¸  PROBLEM: Za maÅ‚o treÅ›ci!")
        
        # Test 2: Metoda z retry
        start_time = time.time()
        retry_content = extractor.extract_with_retry(url, max_retries=2)
        retry_time = time.time() - start_time
        
        print(f"\nMetoda z retry:")
        print(f"  â±ï¸  Czas: {retry_time:.2f}s")
        print(f"  ğŸ“ DÅ‚ugoÅ›Ä‡: {len(retry_content)} znakÃ³w")
        
        if len(retry_content) > len(basic_content):
            if len(basic_content) > 0:
                improvement = ((len(retry_content) - len(basic_content)) / len(basic_content)) * 100
                print(f"  âœ… LEPSZE o {improvement:.0f}%!")
            else:
                print(f"  âœ… LEPSZE (z 0 do {len(retry_content)} znakÃ³w)!")

        # Analiza treÅ›ci
        if retry_content:
            error_phrases = ['javascript', 'enable', 'browser', 'not supported']
            is_error = any(phrase in retry_content.lower()[:200] for phrase in error_phrases)
            
            if is_error:
                print(f"  âš ï¸  Wykryto moÅ¼liwy komunikat bÅ‚Ä™du")
            else:
                print(f"  âœ… TreÅ›Ä‡ wyglÄ…da poprawnie")
        
        time.sleep(1)  # Nie przeciÄ…Å¼aj serwerÃ³w
    
    extractor.close()

if __name__ == "__main__":
    print("DIAGNOSTYKA BOOKMARK PROCESSOR")
    print("=" * 70)
    
    # Test 1: Pojedynczy tweet
    test_single_tweet_analysis()
    
    # Test 2: PorÃ³wnanie metod ekstrakcji
    compare_extraction_methods()
    
    # Test 3: RÃ³Å¼ne prompty
    # test_llm_variations()
    
    print("\nâœ… Diagnostyka zakoÅ„czona!") 