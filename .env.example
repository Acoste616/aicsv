# LLM Provider Configuration
# Wybierz jeden z: local, openai, anthropic, google
LLM_PROVIDER=local

# OpenAI Configuration
OPENAI_API_KEY=your-openai-api-key-here
# Opcjonalnie możesz zmienić model
# OPENAI_MODEL=gpt-3.5-turbo

# Anthropic Configuration
ANTHROPIC_API_KEY=your-anthropic-api-key-here
# Opcjonalnie możesz zmienić model
# ANTHROPIC_MODEL=claude-3-sonnet-20240229

# Google Generative AI Configuration
GOOGLE_API_KEY=your-google-api-key-here
# Opcjonalnie możesz zmienić model
# GOOGLE_MODEL=gemini-pro

# Local LLM Configuration (opcjonalne)
# LOCAL_LLM_URL=http://localhost:1234/v1/chat/completions
# LOCAL_LLM_MODEL=mistralai/mistral-7b-instruct-v0.3

# Cache Configuration
# CACHE_TTL_DAYS=7
# MAX_CACHE_SIZE=10000