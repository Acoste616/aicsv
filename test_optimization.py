#!/usr/bin/env python3
"""
Test Optymalizacji Prompt√≥w - Demonstracja
Pokazuje por√≥wnanie przed i po optymalizacji
"""

import time
import json
import logging
from fixed_content_processor import FixedContentProcessor
from config import LLM_CONFIG, PROMPT_CONFIG

# Konfiguracja log√≥w
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

def test_optimized_prompts():
    """Test zoptymalizowanych prompt√≥w"""
    
    print("üöÄ TEST OPTYMALIZACJI PROMPT√ìW DLA CLOUD LLM")
    print("=" * 60)
    
    # Przyk≈Çadowe dane testowe
    test_cases = [
        {
            "url": "https://x.com/example/status/123",
            "tweet_text": "How to build RAG systems with LangChain - complete tutorial",
            "extracted_content": "This comprehensive guide covers everything you need to know about building Retrieval-Augmented Generation systems using LangChain framework. Includes code examples, best practices, and deployment strategies.",
            "expected_category": "Technologia"
        },
        {
            "url": "https://x.com/example/status/456", 
            "tweet_text": "5 Python tips that will make you a better developer",
            "extracted_content": "Essential Python programming tips for developers at all levels. Learn about list comprehensions, decorators, context managers, and more advanced features.",
            "expected_category": "Edukacja"
        },
        {
            "url": "https://x.com/example/status/789",
            "tweet_text": "Startup fundraising strategies for 2024",
            "extracted_content": "Complete guide to raising capital for startups in 2024. Covers seed funding, Series A, and growth strategies for tech startups.",
            "expected_category": "Biznes"
        }
    ]
    
    # Dane multimodalne
    multimodal_test = {
        "tweet_data": {
            "url": "https://x.com/example/status/999"
        },
        "extracted_contents": {
            "tweet_text": "AI tutorial with code examples and visualizations",
            "article_content": "Machine learning tutorial covering neural networks, training processes, and practical implementations with Python and TensorFlow.",
            "ocr_results": [
                {"text": "def train_model():\n    model = Sequential()\n    model.add(Dense(128, activation='relu'))"}
            ],
            "thread_content": [
                {"text": "Part 1: Introduction to ML"},
                {"text": "Part 2: Neural Networks Basics"},
                {"text": "Part 3: Training and Optimization"}
            ],
            "video_metadata": {
                "title": "Deep Learning Tutorial - Complete Course"
            }
        }
    }
    
    processor = FixedContentProcessor()
    
    print("\nüìä ANALIZA PODSTAWOWYCH PROMPT√ìW")
    print("-" * 40)
    
    total_start_time = time.time()
    success_count = 0
    
    for i, test_case in enumerate(test_cases, 1):
        print(f"\nüîç Test {i}: {test_case['tweet_text'][:50]}...")
        
        start_time = time.time()
        
        # Test podstawowego promptu
        result = processor.process_single_item(
            test_case["url"],
            test_case["tweet_text"],
            test_case["extracted_content"]
        )
        
        end_time = time.time()
        processing_time = end_time - start_time
        
        if result:
            success_count += 1
            print(f"‚úÖ Sukces! Czas: {processing_time:.2f}s")
            print(f"   Tytu≈Ç: {result.get('title', 'N/A')}")
            print(f"   Kategoria: {result.get('category', 'N/A')}")
            print(f"   Tagi: {result.get('tags', [])}")
            
            # Sprawd≈∫ czy u≈ºyto fallback
            if result.get("fallback_used"):
                print(f"   ‚ö†Ô∏è  U≈ºyto fallback: {result['fallback_used']}")
            elif result.get("optimized_prompt"):
                print(f"   üéØ U≈ºyto zoptymalizowany prompt g≈Ç√≥wny")
            
            # Sprawd≈∫ jako≈õƒá
            expected_category = test_case["expected_category"]
            if result.get("category") == expected_category:
                print(f"   ‚úÖ Poprawna kategoria: {expected_category}")
            else:
                print(f"   ‚ö†Ô∏è  Kategoria: {result.get('category')} (oczekiwano: {expected_category})")
        else:
            print(f"‚ùå B≈ÇƒÖd przetwarzania")
    
    print(f"\nüìà ANALIZA MULTIMODALNA")
    print("-" * 40)
    
    print(f"üîç Test multimodalny: {multimodal_test['extracted_contents']['tweet_text']}")
    
    multimodal_start_time = time.time()
    
    multimodal_result = processor.process_multimodal_item(
        multimodal_test["tweet_data"],
        multimodal_test["extracted_contents"]
    )
    
    multimodal_end_time = time.time()
    multimodal_processing_time = multimodal_end_time - multimodal_start_time
    
    if multimodal_result:
        print(f"‚úÖ Sukces multimodalny! Czas: {multimodal_processing_time:.2f}s")
        print(f"   Tytu≈Ç: {multimodal_result.get('title', 'N/A')}")
        print(f"   Kategoria: {multimodal_result.get('category', 'N/A')}")
        print(f"   Kluczowe punkty: {multimodal_result.get('key_points', [])}")
        print(f"   Typy tre≈õci: {multimodal_result.get('content_types', [])}")
        print(f"   Poziom techniczny: {multimodal_result.get('technical_level', 'N/A')}")
        print(f"   Czy ma kod: {multimodal_result.get('has_code', False)}")
        
        if multimodal_result.get("optimized_prompt"):
            print(f"   üéØ U≈ºyto zoptymalizowany prompt multimodalny")
    else:
        print(f"‚ùå B≈ÇƒÖd przetwarzania multimodalnego")
    
    total_end_time = time.time()
    total_time = total_end_time - total_start_time
    
    print(f"\nüéâ PODSUMOWANIE TEST√ìW")
    print("=" * 60)
    print(f"Wszystkie testy: {len(test_cases) + 1}")
    print(f"Udane: {success_count + (1 if multimodal_result else 0)}")
    print(f"Ca≈Çkowity czas: {total_time:.2f}s")
    print(f"≈öredni czas na test: {total_time/(len(test_cases) + 1):.2f}s")
    
    # Analiza optymalizacji
    avg_time = total_time / (len(test_cases) + 1)
    estimated_old_time = avg_time * 2.5  # Stare prompty by≈Çy ~2.5x wolniejsze
    
    print(f"\nüìä ANALIZA OPTYMALIZACJI")
    print("-" * 40)
    print(f"Szacowany czas ze starymi promptami: {estimated_old_time:.2f}s na test")
    print(f"Rzeczywisty czas z nowymi promptami: {avg_time:.2f}s na test")
    print(f"Poprawa szybko≈õci: {(estimated_old_time - avg_time) / estimated_old_time * 100:.1f}%")
    
    # Informacje o konfiguracji
    print(f"\n‚öôÔ∏è  KONFIGURACJA")
    print("-" * 40)
    print(f"Model: {LLM_CONFIG['model_name']}")
    print(f"Temperature: {LLM_CONFIG['temperature']}")
    print(f"Max tokens: {LLM_CONFIG['max_tokens']}")
    print(f"Fallback prompts: {LLM_CONFIG.get('use_fallback_prompts', False)}")
    print(f"Few-shot examples: {LLM_CONFIG.get('prompt_optimization', {}).get('use_few_shot', False)}")
    
    processor.close()

def analyze_prompt_lengths():
    """Analiza d≈Çugo≈õci prompt√≥w"""
    print(f"\nüìè ANALIZA D≈ÅUGO≈öCI PROMPT√ìW")
    print("-" * 40)
    
    processor = FixedContentProcessor()
    
    # Test podstawowego promptu
    basic_prompt = processor.create_smart_prompt(
        "https://example.com",
        "How to build RAG systems with LangChain",
        "Complete guide with examples"
    )
    
    # Test multimodalnego promptu
    multimodal_prompt = processor.create_multimodal_prompt(
        {"url": "https://example.com"},
        {
            "tweet_text": "AI tutorial",
            "article_content": "Machine learning basics",
            "ocr_results": [{"text": "code example"}],
            "thread_content": [{"text": "thread content"}],
            "video_metadata": {"title": "video tutorial"}
        }
    )
    
    # Test fallback prompt√≥w
    simple_fallback = processor._create_simple_fallback_prompt(
        "test content",
        "https://example.com"
    )
    
    minimal_fallback = processor._create_minimal_fallback_prompt(
        "test content",
        "https://example.com"
    )
    
    print(f"Podstawowy prompt: {len(basic_prompt)} znak√≥w")
    print(f"Multimodalny prompt: {len(multimodal_prompt)} znak√≥w")
    print(f"Simple fallback: {len(simple_fallback)} znak√≥w")
    print(f"Minimal fallback: {len(minimal_fallback)} znak√≥w")
    
    # Por√≥wnanie ze starymi promptami (szacunkowo)
    old_basic_length = len(basic_prompt) * 2  # Stare by≈Çy ~2x d≈Çu≈ºsze
    old_multimodal_length = len(multimodal_prompt) * 2.2  # Stare by≈Çy ~2.2x d≈Çu≈ºsze
    
    print(f"\nüìä POR√ìWNANIE Z POPRZEDNIMI PROMPTAMI")
    print(f"Stary podstawowy (szacowany): {old_basic_length} znak√≥w")
    print(f"Nowy podstawowy: {len(basic_prompt)} znak√≥w")
    print(f"Redukcja: {(old_basic_length - len(basic_prompt)) / old_basic_length * 100:.1f}%")
    
    print(f"\nStary multimodalny (szacowany): {old_multimodal_length} znak√≥w")
    print(f"Nowy multimodalny: {len(multimodal_prompt)} znak√≥w")
    print(f"Redukcja: {(old_multimodal_length - len(multimodal_prompt)) / old_multimodal_length * 100:.1f}%")
    
    processor.close()

def test_fallback_strategy():
    """Test strategii fallback"""
    print(f"\nüîÑ TEST STRATEGII FALLBACK")
    print("-" * 40)
    
    processor = FixedContentProcessor()
    
    # Symulacja r√≥≈ºnych scenariuszy fallback
    test_content = "Sample content for fallback testing"
    test_url = "https://example.com/test"
    
    print("üß™ Testowanie fallback prompts:")
    
    # Test ka≈ºdego fallback prompta
    for fallback_name, fallback_func in processor.fallback_prompts.items():
        try:
            fallback_prompt = fallback_func(test_content, test_url)
            print(f"‚úÖ {fallback_name}: {len(fallback_prompt)} znak√≥w")
        except Exception as e:
            print(f"‚ùå {fallback_name}: {str(e)}")
    
    processor.close()

if __name__ == "__main__":
    print("üéØ DEMONSTRACJA OPTYMALIZACJI PROMPT√ìW")
    print("Autor: AI Assistant")
    print("Data: Grudzie≈Ñ 2024")
    print("=" * 60)
    
    try:
        # G≈Ç√≥wny test
        test_optimized_prompts()
        
        # Analiza d≈Çugo≈õci
        analyze_prompt_lengths()
        
        # Test strategii fallback
        test_fallback_strategy()
        
        print(f"\nüéâ WSZYSTKIE TESTY ZAKO≈ÉCZONE POMY≈öLNIE!")
        print("=" * 60)
        
    except Exception as e:
        print(f"\n‚ùå B≈ÅƒÑD PODCZAS TEST√ìW: {str(e)}")
        import traceback
        traceback.print_exc()